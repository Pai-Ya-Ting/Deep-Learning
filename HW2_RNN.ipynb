{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "0852629_RNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jery5237hent/Deep-Learning/blob/main/HW2_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "14ca5950"
      },
      "source": [
        "import torch   \n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchtext.legacy import data   \n",
        "from torchtext.vocab import GloVe\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "torch.manual_seed(2021)\n",
        "torch.cuda.manual_seed(2021)\n",
        "torch.backends.cudnn.deterministic = True  \n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "id": "14ca5950",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0175d6e8"
      },
      "source": [
        "def accuracy(y_pred, y_test):\n",
        "    pred = torch.argmax(y_pred, dim = 1, keepdim = True).squeeze(1)\n",
        "    return (pred == y_test).sum()/len(y_test)"
      ],
      "id": "0175d6e8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7f0ec5c5"
      },
      "source": [
        "def train(data, optimizer, criterion):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    model.train()\n",
        "    for batch in data:\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        text, text_len = batch.title\n",
        "#         print(text_len)\n",
        "        prediction = model(text, text_len)#.squeeze(1)\n",
        "        batch_loss = criterion(prediction, batch.category.squeeze(1))\n",
        "        batch_acc = accuracy(prediction, batch.category.squeeze(1))\n",
        "\n",
        "        batch_loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), 0.01)\n",
        "        optimizer.step()\n",
        "        \n",
        "        \n",
        "        epoch_loss += batch_loss.item()\n",
        "        epoch_acc += batch_acc.item()\n",
        "\n",
        "    return epoch_loss / len(data), epoch_acc / len(data)"
      ],
      "id": "7f0ec5c5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b68e4766"
      },
      "source": [
        "def predict(data, model):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    ans = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch in data:\n",
        "            text, text_len = batch.title\n",
        "            prediction = model(text, text_len).squeeze(1)\n",
        "            pred = torch.argmax(prediction, dim = 1, keepdim = True).squeeze(1)\n",
        "            ans.extend(list(map(lambda x: category.vocab.itos[x], pred)))\n",
        "            \n",
        "        return pd.DataFrame(ans, columns=['Category'])"
      ],
      "id": "b68e4766",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3074ea2a"
      },
      "source": [
        "def evaluate(data, optimizer, criterion):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch in data:\n",
        "            text, text_len = batch.title\n",
        "            prediction = model(text, text_len).squeeze(1)\n",
        "\n",
        "            batch_loss = criterion(prediction, batch.category.squeeze(1))\n",
        "            batch_acc = accuracy(prediction, batch.category.squeeze(1))\n",
        "            \n",
        "            epoch_loss += batch_loss.item()\n",
        "            epoch_acc += batch_acc.item()\n",
        "        return epoch_loss / len(data), epoch_acc / len(data)"
      ],
      "id": "3074ea2a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9eb60f6"
      },
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, vocab_size, n_class):\n",
        "        super(RNN, self).__init__()\n",
        "\n",
        "        hidden_size = 128\n",
        "\n",
        "        self.embedding = vocab.vectors\n",
        "#         self.lstm1 = nn.LSTM(vocab.vectors.shape[1], hidden_size, 2, bidirectional = True, batch_first=True)\n",
        "        \n",
        "        self.gru1 = nn.GRU(vocab.vectors.shape[1], int(hidden_size/2), bidirectional=True, batch_first=True)\n",
        "        \n",
        "        self.w_omega = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
        "        nn.init.uniform_(self.w_omega, -0.1, 0.1)\n",
        "        self.u_omega = nn.Parameter(torch.Tensor(hidden_size, 1))\n",
        "        nn.init.uniform_(self.u_omega, -0.1, 0.1)\n",
        "\n",
        "#         self.lstm2 = nn.LSTM(hidden_size * 2, hidden_size, 2, bidirectional = True, batch_first=True)\n",
        "        self.gru2 = nn.GRU(hidden_size, int(hidden_size/2), bidirectional=True, batch_first=True)\n",
        "        \n",
        "        self.fc = nn.Linear(hidden_size, n_class)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "#         self.conv = nn.Conv1d(in_channels=vocab.vectors.shape[1]ï¼Œout_channels=hidden_size,kernel_size=3, stride = 2)\n",
        "        \n",
        "    def forward(self, text, text_len):\n",
        "        outputs = self.embedding[text]\n",
        "#         outputs = self.ln1(outputs)\n",
        "#         outputs, _ = self.lstm1(outputs)\n",
        "        outputs = outputs.to(device)\n",
        "        outputs, _ = self.gru1(outputs)\n",
        "        # Attention\n",
        "        u = torch.tanh(torch.matmul(outputs, self.w_omega)) #batch_size, seq_len, 2 * num_hiddens\n",
        "        att = torch.matmul(u, self.u_omega) #batch_size, seq_len, 1\n",
        "        att_score = F.softmax(att, dim=1) #batch_size, seq_len, 1\n",
        "        scored_x = outputs * att_score #batch_size, seq_len, 2 * num_hiddens\n",
        "        # Attention\n",
        "        outputs = torch.sum(scored_x, dim=1) # batch_size * batch_size\n",
        "        outputs = torch.unsqueeze(outputs, 1)\n",
        "        outputs, _ = self.gru2(outputs)\n",
        "        outputs = torch.mean(outputs, dim = 1)\n",
        "        outputs = self.fc(outputs) # batch_size * 5  \n",
        "        outputs = F.silu(outputs)\n",
        "#         outputs= torch.tanh(outputs) # batch_size * 5\n",
        "\n",
        "        return outputs"
      ],
      "id": "f9eb60f6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ce2f5c91"
      },
      "source": [
        "def build_dict():\n",
        "    category.build_vocab(train_data)\n",
        "    title.build_vocab(train_data, test_data, vectors = GloVe())#, unk_init=torch.Tensor.normal_)\n",
        "    \n",
        "    vocab = title.vocab\n",
        "    vocab_size = len(title.vocab)\n",
        "    n_class = len(category.vocab)\n",
        "    \n",
        "    PAD_IDX= vocab.stoi[title.pad_token]\n",
        "    UNK_IDX = vocab.stoi[title.unk_token]\n",
        "\n",
        "    vocab.vectors[UNK_IDX]=torch.zeros(vocab.vectors.shape[1])\n",
        "    vocab.vectors[PAD_IDX]=torch.zeros(vocab.vectors.shape[1])\n",
        "    \n",
        "    return vocab_size, vocab, n_class"
      ],
      "id": "ce2f5c91",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6a0f6ca"
      },
      "source": [
        "def prepare_data(train, test):\n",
        "    train = data.BucketIterator(\n",
        "      (train),\n",
        "      sort_key = lambda x: len(x.title),\n",
        "      sort = True,\n",
        "      sort_within_batch=True,\n",
        "      batch_size = 64,\n",
        "      device = device\n",
        "    )\n",
        "\n",
        "    test = data.BucketIterator(\n",
        "      (test),\n",
        "      batch_size = 64,\n",
        "        sort = False,\n",
        "        sort_within_batch=False,\n",
        "        shuffle=False,\n",
        "      device = device\n",
        "    )\n",
        "    \n",
        "    return train, test"
      ],
      "id": "c6a0f6ca",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nVlkXRo-GT-"
      },
      "source": [
        "# !pip install spacy-transformers\n",
        "# !python -m spacy download en_core_web_trf"
      ],
      "id": "0nVlkXRo-GT-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81772034"
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en_core_web_trf')\n",
        "stop_words = nlp.Defaults.stop_words"
      ],
      "id": "81772034",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "70f51bbc"
      },
      "source": [
        "category = data.Field(batch_first=True, pad_token=None, unk_token=None)\n",
        "title = data.Field(tokenize='spacy', tokenizer_language='en_core_web_trf', fix_length=10, #stop_words=stop_words,\n",
        "                   batch_first=True, lower= True, include_lengths=True, init_token='<sos>', eos_token='<eos>')\n",
        "# title = data.Field(fix_length=10, stop_words=stop_words,\n",
        "#                    batch_first=True, lower= True, include_lengths=True, init_token='<sos>', eos_token='<eos>')\n",
        "\n",
        "train_data = data.TabularDataset(\n",
        "   path = 'news_data/train.csv',\n",
        "   format = 'csv',\n",
        "   fields = [(None, None), ('category', category), ('title', title)],\n",
        "   skip_header = True\n",
        ")\n",
        "\n",
        "test_data = data.TabularDataset(\n",
        "   path = 'news_data/test.csv',\n",
        "   format = 'csv',\n",
        "   fields = [(None, None), ('title', title)],\n",
        "   skip_header = True\n",
        ")\n",
        "\n",
        "# # check an example\n",
        "# print(vars(test_data[0]))"
      ],
      "id": "70f51bbc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49550dec",
        "outputId": "3a5f7caa-0149-4849-b6c7-80e22f012b5b"
      },
      "source": [
        "# best_loss = float('inf')\n",
        "# train_loss = train_acc = 0\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "vocab_size, vocab, n_class = build_dict()\n",
        "# n_class"
      ],
      "id": "49550dec",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".vector_cache/glove.840B.300d.zip: 2.18GB [07:30, 4.83MB/s]                            \n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 2195724/2196017 [04:00<00:00, 10063.94it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yLGkiKwCSy5"
      },
      "source": [
        "# train_set, valid_set = train_data.split(split_ratio=0.8, random_state=random.getstate())"
      ],
      "id": "-yLGkiKwCSy5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "160ebccc"
      },
      "source": [
        "# N_EPOCHS = 15\n",
        "# model = RNN(vocab_size, n_class).to(device)\n",
        "# # optimizer = optim.SGD(model.parameters(), lr=1e-4, momentum=0.9)\n",
        "# # optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-3)\n",
        "\n",
        "# optimizer = optim.RMSprop(model.parameters(), lr = 1e-4, weight_decay=1e-4)\n",
        "# training_data, testing_data = prepare_data(train_set, valid_set)\n",
        "# # scheduler = optim.lr_scheduler.ExponentialLR(optimizer, 0.1)\n",
        "    \n",
        "# l_train, acc_train = [], []\n",
        "# l_valid, acc_valid = [], []\n",
        "\n",
        "# for epoch in range(N_EPOCHS):\n",
        "\n",
        "#     train_loss, train_acc = train(training_data, optimizer, criterion)\n",
        "#     valid_loss, valid_acc = evaluate(testing_data, optimizer, criterion)\n",
        "#     # scheduler.step()\n",
        "#     if valid_loss < best_loss:\n",
        "#         best_loss = valid_loss\n",
        "#         best_model = model\n",
        "    \n",
        "#     acc_train.append(train_acc)\n",
        "#     l_train.append(train_loss)\n",
        "\n",
        "#     acc_valid.append(valid_acc)\n",
        "#     l_valid.append(valid_loss)\n",
        "\n",
        "#     print(f'Epoch: {epoch+1}')\n",
        "#     print('learning rate: ', optimizer.param_groups[0]['lr'])\n",
        "#     print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "#     print(f'\\tValid Loss: {valid_loss:.3f} | Valid Acc: {valid_acc*100:.2f}%')"
      ],
      "id": "160ebccc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01QCIpfLhQiT"
      },
      "source": [
        "# plt.plot(l_train)\n",
        "# plt.plot(l_valid)"
      ],
      "id": "01QCIpfLhQiT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQOhQ5bQhbDT"
      },
      "source": [
        "# plt.plot(acc_train)\n",
        "# plt.plot(acc_valid)"
      ],
      "id": "sQOhQ5bQhbDT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cbe597a"
      },
      "source": [
        "training_data, testing_data = prepare_data(train_data, test_data)\n",
        "model = RNN(vocab_size, n_class).to(device)\n",
        "model.load_state_dict(torch.load('RNN_9189.pt',  map_location=torch.device(device)))\n",
        "# train_loss, train_acc = train(training_data, optimizer, criterion)\n",
        "\n",
        "ans = predict(testing_data, model)\n",
        "ans.insert(0, column=\"Id\", value = ans.index.values)\n",
        "ans.to_csv('0852629_submission_RNN.csv', index = False)"
      ],
      "id": "6cbe597a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52b73796"
      },
      "source": [
        "# torch.save(model.state_dict(), 'model_weight_9189.pt')"
      ],
      "id": "52b73796",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AeE2BZmVFt0M"
      },
      "source": [
        ""
      ],
      "id": "AeE2BZmVFt0M",
      "execution_count": null,
      "outputs": []
    }
  ]
}